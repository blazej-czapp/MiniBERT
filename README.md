Just playing with training models. Training a small BERT with Masked Language Model head to learn embeddings, then swapping the head for a Named Entity Recogniser head (TODO).
